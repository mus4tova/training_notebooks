# training_projects

These small notebooks were created at the beginning of my prefessional journey to familiarize myself with classical machine learning algorithms, strengthen my skills, gain practical experience, and better understand the essence and principles of core ML algorithms. Later, as I progressed professionally, I made some improvements to my initial projects, increased the metrics, and added deeper data analysis.

1. Click prediction: binary classification task; exploratory data analysis (EDA); models: logistic regression, neural network
2. Credits score: multiclass classification task;EDA; models: KNeighborsClassifier, naive Bayes, logistic regression, random forest with hyperparameter tuning
3. Customer segmentation: clustering; EDA; models: k- means
4. Diabetes prediction: binary classification task; EDA; models: KNeighborsClassifier, naive Bayes, catboost, random forest, support vector machine
5. Fake news prediction: nlp, binary classification; stemming; vectorizing; models: logistic regression
6. House price prediction: regression task; EDA; models: random forest, XGBoost, linear regression, LGBM regressor, neural network, catboost, 
ridge regression, BayesianRidge,svm
7. IMDb review classification: nlp, binary classification task; vectorizing; models: neural network with embedding layer and without
8. Insurance cost prediction: regression task; EDA; models: random forest, XGBoost, linear regression, LGBM regressor, neural network, catboost, 
ridge regression, BayesianRidge, svm
9. Iris species: multiclass classification task (3 classes); KNeighborsClassifier, naive Bayes, logistic regression, random forest, LinearSVC
10. MNIST recognasing: CV, multiclass classification (10 classes); models: neural network
11. Spam mail prediction: nlp, binary classification task; vectorizing; models: logistic regression
12. Titanic: binary classification task; EDA; models: keras neural network, random forest and logistic regression with hyperparameter tuning

